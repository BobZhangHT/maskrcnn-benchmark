{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## debug the transformation problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```bash\n",
    "File \"/home/r7user3/ZhangHT/github/maskrcnn-benchmark/maskrcnn_benchmark/engine/trainer.py\", line 118, in do_train\n",
    "    for iteration, (images, targets, _) in enumerate(data_loader, start_iter):\n",
    "  File \"/home/r7user3/anaconda2/envs/maskrcnn/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 615, in __next__\n",
    "    batch = self.collate_fn([self.dataset[i] for i in indices])\n",
    "  File \"/home/r7user3/anaconda2/envs/maskrcnn/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 615, in <listcomp>\n",
    "    batch = self.collate_fn([self.dataset[i] for i in indices])\n",
    "  File \"/home/r7user3/ZhangHT/github/maskrcnn-benchmark/maskrcnn_benchmark/data/datasets/coco.py\", line 61, in __getitem__\n",
    "    img, target = self.transforms(img, target)\n",
    "  File \"/home/r7user3/ZhangHT/github/maskrcnn-benchmark/maskrcnn_benchmark/data/transforms/transforms.py\", line 19, in __call__\n",
    "    image, target = t(image, target)\n",
    "  File \"/home/r7user3/ZhangHT/github/maskrcnn-benchmark/maskrcnn_benchmark/data/transforms/transforms.py\", line 95, in __call__\n",
    "    target=F.rotate(target,angle)\n",
    "  File \"/home/r7user3/anaconda2/envs/maskrcnn/lib/python3.7/site-packages/torchvision/transforms/functional.py\", line 593, in rotate\n",
    "    raise TypeError('img should be PIL Image. Got {}'.format(type(img)))\n",
    "TypeError: img should be PIL Image. Got <class 'maskrcnn_benchmark.structures.bounding_box.BoxList'>\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train_net.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from maskrcnn_benchmark.config import cfg\n",
    "import os\n",
    "import torch\n",
    "from maskrcnn_benchmark.data import make_data_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# simulate the true working dir\n",
    "os.chdir('/home/r7user3/ZhangHT/github/maskrcnn-benchmark/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg.merge_from_file('./configs/e2e_mask_rcnn_R_50_FPN_1x.yaml')\n",
    "cfg.freeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "distributed=False\n",
    "start_iter=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "When using more than one image per GPU you may encounter an out-of-memory (OOM) error if your GPU does not have sufficient memory. If this happens, you can reduce SOLVER.IMS_PER_BATCH (for training) or TEST.IMS_PER_BATCH (for inference). For training, you must also adjust the learning rate and schedule length according to the linear scaling rule. See for example: https://github.com/facebookresearch/Detectron/blob/master/configs/getting_started/tutorial_1gpu_e2e_faster_rcnn_R-50-FPN.yaml#L14\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.37s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    }
   ],
   "source": [
    "data_loader = make_data_loader(\n",
    "        cfg,\n",
    "        is_train=True,\n",
    "        is_distributed=distributed,\n",
    "        start_iter=start_iter,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### trainer.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataiter=enumerate(data_loader, start_iter)\n",
    "_,(images,targets,_)=next(dataiter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "target=targets[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mask=target.get_field('masks')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([125., 116., 124., 117., 123., 117., 122., 118., 122., 119., 122., 120.,\n",
       "         122., 121., 122., 122., 122., 123., 122., 124., 123., 124., 124., 125.,\n",
       "         125., 125., 126., 125., 127., 125., 128., 125., 129., 124., 129., 123.,\n",
       "         129., 122., 128., 121., 127., 120., 126., 119., 126., 118., 126., 117.])]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#mask.polygons[0].polygons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=torch.Tensor(1,28,28)\n",
    "b=a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 28, 28)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tuple(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## multi train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```bash\n",
    "CUDA_VISIBLE_DEVICES=2,3 python -m torch.distributed.launch --nproc_per_node=2 --master_addr 127.0.0.2 --master_port 29501 tools/train_net.py --config-file configs/e2e_mask_rcnn_R_50_FPN_1x.yaml SOLVER.IMS_PER_BATCH 4 SOLVER.BASE_LR 0.005 SOLVER.MAX_ITER 30000 SOLVER.STEPS \"(15000, 20000)\" TEST.IMS_PER_BATCH 2\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```bash\n",
    "python tools/train_net.py --config-file \"configs/e2e_mask_rcnn_R_50_FPN_1x.yaml\" SOLVER.IMS_PER_BATCH 2 SOLVER.BASE_LR 0.0025 SOLVER.MAX_ITER 60000 SOLVER.STEPS \"(30000, 40000)\" TEST.IMS_PER_BATCH 1\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pycocotools.coco import COCO\n",
    "from maskrcnn_benchmark.config import cfg\n",
    "import os\n",
    "import torch\n",
    "from maskrcnn_benchmark.data import make_data_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.17s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    }
   ],
   "source": [
    "coco=COCO('./train.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# simulate the true working dir\n",
    "os.chdir('/home/r7user3/ZhangHT/github/maskrcnn-benchmark/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a=torch.rand(2,3,256,256)\n",
    "a.dim()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3, 256, 256])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(196345.0781)\n"
     ]
    }
   ],
   "source": [
    "print(a.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "True or False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
