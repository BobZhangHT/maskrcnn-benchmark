{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## debug the transformation problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```bash\n",
    "File \"/home/r7user3/ZhangHT/github/maskrcnn-benchmark/maskrcnn_benchmark/engine/trainer.py\", line 118, in do_train\n",
    "    for iteration, (images, targets, _) in enumerate(data_loader, start_iter):\n",
    "  File \"/home/r7user3/anaconda2/envs/maskrcnn/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 615, in __next__\n",
    "    batch = self.collate_fn([self.dataset[i] for i in indices])\n",
    "  File \"/home/r7user3/anaconda2/envs/maskrcnn/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 615, in <listcomp>\n",
    "    batch = self.collate_fn([self.dataset[i] for i in indices])\n",
    "  File \"/home/r7user3/ZhangHT/github/maskrcnn-benchmark/maskrcnn_benchmark/data/datasets/coco.py\", line 61, in __getitem__\n",
    "    img, target = self.transforms(img, target)\n",
    "  File \"/home/r7user3/ZhangHT/github/maskrcnn-benchmark/maskrcnn_benchmark/data/transforms/transforms.py\", line 19, in __call__\n",
    "    image, target = t(image, target)\n",
    "  File \"/home/r7user3/ZhangHT/github/maskrcnn-benchmark/maskrcnn_benchmark/data/transforms/transforms.py\", line 95, in __call__\n",
    "    target=F.rotate(target,angle)\n",
    "  File \"/home/r7user3/anaconda2/envs/maskrcnn/lib/python3.7/site-packages/torchvision/transforms/functional.py\", line 593, in rotate\n",
    "    raise TypeError('img should be PIL Image. Got {}'.format(type(img)))\n",
    "TypeError: img should be PIL Image. Got <class 'maskrcnn_benchmark.structures.bounding_box.BoxList'>\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train_net.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from maskrcnn_benchmark.config import cfg\n",
    "import os\n",
    "import torch\n",
    "from maskrcnn_benchmark.utils.comm import get_world_size\n",
    "from maskrcnn_benchmark.data import make_data_loader\n",
    "from maskrcnn_benchmark.modeling.detector import build_detection_model\n",
    "from maskrcnn_benchmark.solver import make_lr_scheduler\n",
    "from maskrcnn_benchmark.solver import make_optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_loss_dict(loss_dict):\n",
    "    \"\"\"\n",
    "    Reduce the loss dictionary from all processes so that process with rank\n",
    "    0 has the averaged results. Returns a dict with the same fields as\n",
    "    loss_dict, after reduction.\n",
    "    \"\"\"\n",
    "    world_size = get_world_size()\n",
    "    if world_size < 2:\n",
    "        return loss_dict\n",
    "    with torch.no_grad():\n",
    "        loss_names = []\n",
    "        all_losses = []\n",
    "        for k in sorted(loss_dict.keys()):\n",
    "            loss_names.append(k)\n",
    "            all_losses.append(loss_dict[k])\n",
    "        all_losses = torch.stack(all_losses, dim=0)\n",
    "        dist.reduce(all_losses, dst=0)\n",
    "        if dist.get_rank() == 0:\n",
    "            # only main process gets accumulated, so only divide by\n",
    "            # world_size in this case\n",
    "            all_losses /= world_size\n",
    "        reduced_losses = {k: v for k, v in zip(loss_names, all_losses)}\n",
    "    return reduced_losses\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# simulate the true working dir\n",
    "os.chdir('/home/r7user3/ZhangHT/github/maskrcnn-benchmark/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg.merge_from_file('./configs/e2e_mask_rcnn_R_50_FPN_1x.yaml')\n",
    "cfg.freeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "distributed=False\n",
    "start_iter=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "When using more than one image per GPU you may encounter an out-of-memory (OOM) error if your GPU does not have sufficient memory. If this happens, you can reduce SOLVER.IMS_PER_BATCH (for training) or TEST.IMS_PER_BATCH (for inference). For training, you must also adjust the learning rate and schedule length according to the linear scaling rule. See for example: https://github.com/facebookresearch/Detectron/blob/master/configs/getting_started/tutorial_1gpu_e2e_faster_rcnn_R-50-FPN.yaml#L14\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.06s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    }
   ],
   "source": [
    "data_loader = make_data_loader(\n",
    "        cfg,\n",
    "        is_train=True,\n",
    "        is_distributed=distributed,\n",
    "        start_iter=start_iter,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### trainer.py\n",
    "\n",
    "This Problem is caused by **too large** learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model=build_detection_model(cfg)\n",
    "device = torch.device(cfg.MODEL.DEVICE)\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.to(device)\n",
    "optimizer = make_optimizer(cfg, model)\n",
    "scheduler = make_lr_scheduler(cfg, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration: 1\n",
      "cp1\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: device-side assert triggered",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-5749e263541a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cp1'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m     \u001b[0mimages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m     \u001b[0mtargets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cp2'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/ZhangHT/github/maskrcnn-benchmark/maskrcnn_benchmark/structures/image_list.py\u001b[0m in \u001b[0;36mto\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m         \u001b[0mcast_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mImageList\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcast_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage_sizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered"
     ]
    }
   ],
   "source": [
    "max_iter = 100\n",
    "start_iter = 0 # 0 at start\n",
    "\n",
    "model.train() # begin training\n",
    "\n",
    "######################################################################################################################\n",
    "# Note: once begin training, rank of GPU will change iteratively! So the rank of GPU is 0 above this comment.\n",
    "#       Moreover, iteration is counted following rank 0 GPU. In other words, all checkpoint work on cuda:0.\n",
    "######################################################################################################################\n",
    "for iteration, (images, targets,_) in enumerate(data_loader,0):\n",
    "    \n",
    "\n",
    "    iteration = iteration + 1\n",
    "    print('iteration:',iteration)\n",
    "\n",
    "    scheduler.step()\n",
    "    print('cp1')\n",
    "\n",
    "    images = images.to(device)\n",
    "    targets = [target.to(device) for target in targets]\n",
    "    print('cp2')\n",
    "    loss_dict = model(images, targets)\n",
    "\n",
    "    losses = sum(loss for loss in loss_dict.values())\n",
    "\n",
    "    # reduce losses over all GPUs for logging purposes\n",
    "    loss_dict_reduced = reduce_loss_dict(loss_dict)\n",
    "    losses_reduced = sum(loss for loss in loss_dict_reduced.values())\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    losses.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if iteration % 20 == 0 or iteration == max_iter:\n",
    "        print('Loss',losses.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## multi train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Learning rate is too large, suggest to be 0.0025.\n",
    "```bash\n",
    "CUDA_VISIBLE_DEVICES=2,3 python -m torch.distributed.launch --nproc_per_node=2 --master_addr 127.0.0.2 --master_port 29501 tools/train_net.py --config-file configs/e2e_mask_rcnn_R_50_FPN_1x.yaml SOLVER.IMS_PER_BATCH 4 SOLVER.BASE_LR 0.005 SOLVER.MAX_ITER 30000 SOLVER.STEPS \"(15000, 20000)\" TEST.IMS_PER_BATCH 2\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```bash\n",
    "python tools/train_net.py --config-file \"configs/e2e_mask_rcnn_R_50_FPN_1x.yaml\" SOLVER.BASE_LR 0.0025 SOLVER.MAX_ITER 60000 SOLVER.STEPS \"(30000, 40000)\" TEST.IMS_PER_BATCH 1\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```bash\n",
    "python tools/train_net.py --config-file \"configs/e2e_mask_rcnn_R_50_FPN_1x.yaml\" SOLVER.BASE_LR 0.0025 TEST.IMS_PER_BATCH 1\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```bash\n",
    "CUDA_VISIBLE_DEVICES=2,3 python -m torch.distributed.launch --nproc_per_node=2 --master_addr 127.0.0.2 --master_port 29501 tools/train_net.py --config-file configs/e2e_mask_rcnn_R_50_FPN_1x.yaml SOLVER.BASE_LR 0.0025 SOLVER.IMS_PER_BATCH 4 TEST.IMS_PER_BATCH 2\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from maskrcnn_benchmark.config import cfg\n",
    "from maskrcnn_benchmark.data import make_data_loader\n",
    "from maskrcnn_benchmark.engine.inference import inference\n",
    "from maskrcnn_benchmark.modeling.detector import build_detection_model\n",
    "from maskrcnn_benchmark.utils.checkpoint import DetectronCheckpointer\n",
    "\n",
    "from maskrcnn_benchmark.utils.validation import EvalMetric\n",
    "from maskrcnn_benchmark.modeling.roi_heads.mask_head.inference import Masker\n",
    "\n",
    "from maskrcnn_benchmark.config.paths_catalog import DatasetCatalog\n",
    "from pycocotools.coco import COCO\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('/home/r7user3/ZhangHT/github/maskrcnn-benchmark/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg.merge_from_file('./configs/e2e_mask_rcnn_R_50_FPN_1x.yaml')\n",
    "cfg.merge_from_list(['MODEL.WEIGHT',\"./logs/rectal_benchmark/model_final.pth\",'TEST.IMS_PER_BATCH',1])\n",
    "cfg.freeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./logs/rectal_benchmark/model_final.pth'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfg.MODEL.WEIGHT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "iou_types = (\"bbox\",)\n",
    "if cfg.MODEL.MASK_ON:\n",
    "    iou_types = iou_types + (\"segm\",)\n",
    "    dataset_name = cfg.DATASETS.VAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    }
   ],
   "source": [
    "model = build_detection_model(cfg)\n",
    "model.to(cfg.MODEL.DEVICE)\n",
    "data_loader_val = make_data_loader(cfg, is_train=False, is_val=True)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = './'\n",
    "checkpointer = DetectronCheckpointer(cfg, model, save_dir=output_dir)\n",
    "_ = checkpointer.load(cfg.MODEL.WEIGHT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 84/84 [00:07<00:00, 10.97it/s]\n"
     ]
    }
   ],
   "source": [
    "predictions=inference(\n",
    "                        model,\n",
    "                        data_loader_val,\n",
    "                        dataset_name=dataset_name,\n",
    "                        iou_types=iou_types,\n",
    "                        box_only=cfg.MODEL.RPN_ONLY,\n",
    "                        device=cfg.MODEL.DEVICE,\n",
    "                        expected_results=cfg.TEST.EXPECTED_RESULTS,\n",
    "                        expected_results_sigma_tol=cfg.TEST.EXPECTED_RESULTS_SIGMA_TOL,\n",
    "                        only_predictions=True\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Loading the masks...\n",
      "Loading Complete!\n"
     ]
    }
   ],
   "source": [
    "_,ann_file=DatasetCatalog.DATASETS[cfg.DATASETS.VAL[0]].values()\n",
    "data_dir=DatasetCatalog.DATA_DIR\n",
    "annFile=data_dir+'/'+ann_file\n",
    "\n",
    "coco=COCO(annFile)\n",
    "imgIds=coco.getImgIds()\n",
    "imgsInfo=coco.loadImgs(imgIds)\n",
    "whs=[(img['width'],img['height']) for img in imgsInfo]\n",
    "\n",
    "print('Loading the masks...')\n",
    "masksgt=[]\n",
    "for i,imgId in enumerate(imgIds):\n",
    "    annIds=coco.getAnnIds(imgIds=imgId)\n",
    "    anns=coco.loadAnns(annIds)\n",
    "    maskgt=[]\n",
    "    for ann in anns:\n",
    "        maskgt.append(coco.annToMask(ann))\n",
    "    masksgt.append((np.sum(maskgt,0)>0).astype(np.uint8))\n",
    "print('Loading Complete!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading the predictions...\n",
      "Loading Complete!\n"
     ]
    }
   ],
   "source": [
    "masker=Masker(cfg.EVAL_THRESHOLD)\n",
    "print('Loading the predictions...')\n",
    "masksdt=[]\n",
    "for i,prediction in enumerate(predictions):\n",
    "    prediction=prediction.resize(whs[i])\n",
    "    if not len(prediction):\n",
    "        # if num of box is 0, there is no mask (2019/01/16)\n",
    "        maskdt=np.zeros(tuple(whs[i][::-1]),dtype=np.uint8)\n",
    "    else:\n",
    "        maskdt=prediction.get_field('mask')\n",
    "        if list(maskdt.shape[-2:]) != list(whs[i][::-1]):\n",
    "            maskdt = masker(maskdt.expand(1, -1, -1, -1, -1), prediction)\n",
    "            maskdt = maskdt[0]\n",
    "        maskdt=maskdt.numpy().sum((0,1))\n",
    "        maskdt=(maskdt>0).astype(np.uint8)\n",
    "    masksdt.append(maskdt)\n",
    "print('Loading Complete!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_dice=EvalMetric(masksgt,masksdt).mean_dice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5960018956931298"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_dice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
